{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3834ef6-c956-42c2-a453-321483bf274b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, trim, current_timestamp, lit, expr, md5, \n",
    "    coalesce, concat_ws, row_number, split, array_distinct, \n",
    "    array_remove, size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "770335b7-00db-4427-bdfe-29e744d4dd64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. CONFIG\n",
    "# ============================================================\n",
    "\n",
    "RAW_DATA_PATH = \"/Volumes/workspace/damg7370/datastore/IMDB/title.crew.tsv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b84b970d-19e2-48da-8469-a4f734c8b73e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. BRONZE LAYER\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_title_crew\",\n",
    "    comment=\"Bronze table for IMDb title.crew - raw data plus audit columns\",\n",
    "    table_properties={\n",
    "        \"quality\": \"bronze\",\n",
    "        \"pipelines.autoOptimize.zOrderCols\": \"tconst\"\n",
    "    }\n",
    ")\n",
    "def bronze_title_crew():\n",
    "    \"\"\"\n",
    "    Bronze layer: Raw data ingestion from title.crew.tsv\n",
    "    \"\"\"\n",
    "    df_raw = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .csv(RAW_DATA_PATH)\n",
    "    )\n",
    "\n",
    "    # Convert empty strings to NULL\n",
    "    df_raw = (\n",
    "        df_raw\n",
    "        .withColumn(\"directors\", when(trim(col(\"directors\")) == \"\", None).otherwise(col(\"directors\")))\n",
    "        .withColumn(\"writers\", when(trim(col(\"writers\")) == \"\", None).otherwise(col(\"writers\")))\n",
    "    )\n",
    "\n",
    "    df_bronze = (\n",
    "        df_raw\n",
    "        .withColumn(\"bronze_ingestion_timestamp\", current_timestamp())\n",
    "        .withColumn(\"bronze_ingestion_date\", current_timestamp().cast(\"date\"))\n",
    "        .withColumn(\"bronze_source_system\", lit(\"imdb\"))\n",
    "        .withColumn(\"bronze_source_file\", lit(RAW_DATA_PATH))\n",
    "        .withColumn(\n",
    "            \"bronze_record_hash\",\n",
    "            md5(\n",
    "                concat_ws(\n",
    "                    \"|\",\n",
    "                    coalesce(col(\"tconst\"), lit(\"\")),\n",
    "                    coalesce(col(\"directors\"), lit(\"\")),\n",
    "                    coalesce(col(\"writers\"), lit(\"\"))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df_bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1aa77d3d-5b7b-4c54-89cc-3d97efec5894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. CLEANING HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def validate_tconst(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Validate TCONST format\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"tconst_valid\",\n",
    "        when(col(\"tconst\").isNotNull() & col(\"tconst\").rlike(\"^tt[0-9]+$\"), True).otherwise(False)\n",
    "    )\n",
    "\n",
    "def clean_tconst(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and standardize TCONST\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"tconst_clean\",\n",
    "        when(col(\"tconst\").isNotNull(), trim(col(\"tconst\"))).otherwise(None)\n",
    "    )\n",
    "\n",
    "def parse_directors(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Parse directors into array and count\"\"\"\n",
    "    df = df.withColumn(\n",
    "        \"directors_array\",\n",
    "        when(col(\"directors\").isNotNull(),\n",
    "             array_distinct(array_remove(split(col(\"directors\"), \",\"), \"\")))\n",
    "        .otherwise(expr(\"array()\"))\n",
    "    )\n",
    "    df = df.withColumn(\"directors_count\", size(col(\"directors_array\")))\n",
    "    return df\n",
    "\n",
    "def parse_writers(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Parse writers into array and count\"\"\"\n",
    "    df = df.withColumn(\n",
    "        \"writers_array\",\n",
    "        when(col(\"writers\").isNotNull(),\n",
    "             array_distinct(array_remove(split(col(\"writers\"), \",\"), \"\")))\n",
    "        .otherwise(expr(\"array()\"))\n",
    "    )\n",
    "    df = df.withColumn(\"writers_count\", size(col(\"writers_array\")))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2b33da8-ce0c-4bd5-b24b-d607e78e9f28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. SILVER ALL (CLEANED + QUALITY FLAGS)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_crew\",\n",
    "    comment=\"Silver cleaned table with quality scoring\",\n",
    "    table_properties={\n",
    "        \"quality\": \"silver\",\n",
    "        \"pipelines.autoOptimize.zOrderCols\": \"tconst\"\n",
    "    }\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_tconst_not_null\", \"tconst IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_tconst_format\", \"tconst RLIKE '^tt[0-9]+$'\")\n",
    "def silver_title_crew():\n",
    "    \"\"\"\n",
    "    Silver layer: Clean and validate data with quality scoring\n",
    "    NULLs are kept as-is here, will be replaced in silver_clean\n",
    "    \"\"\"\n",
    "    df = dlt.read(\"bronze_title_crew\")\n",
    "\n",
    "    df = validate_tconst(df)\n",
    "    df = clean_tconst(df)\n",
    "    df = parse_directors(df)\n",
    "    df = parse_writers(df)\n",
    "\n",
    "    # Quality scoring\n",
    "    df = df.withColumn(\n",
    "        \"data_completeness_score\",\n",
    "        (\n",
    "            when(col(\"tconst_valid\"), 40).otherwise(0)\n",
    "            + when(col(\"directors_count\") > 0, 30).otherwise(0)\n",
    "            + when(col(\"writers_count\") > 0, 30).otherwise(0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"quality_tier\",\n",
    "        when(col(\"data_completeness_score\") >= 70, \"HIGH\")\n",
    "        .when(col(\"data_completeness_score\") >= 40, \"MEDIUM\")\n",
    "        .otherwise(\"LOW\")\n",
    "    )\n",
    "\n",
    "    # Metadata\n",
    "    df = df.withColumn(\"silver_processing_timestamp\", current_timestamp())\n",
    "    df = df.withColumn(\"silver_processing_date\", current_timestamp().cast(\"date\"))\n",
    "    df = df.withColumn(\"silver_version\", lit(\"1.0\"))\n",
    "\n",
    "    # Quality check\n",
    "    df = df.withColumn(\n",
    "        \"silver_quality_check\",\n",
    "        when(~col(\"tconst_valid\"), \"FAILED\")\n",
    "        .when(col(\"quality_tier\") == \"LOW\", \"FAILED\")\n",
    "        .otherwise(\"PASSED\")\n",
    "    )\n",
    "\n",
    "    # Deduplicate by tconst\n",
    "    w = Window.partitionBy(\"tconst\").orderBy(col(\"bronze_ingestion_timestamp\").desc())\n",
    "    df = df.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5aba47a2-b9b2-4730-bbd5-3427ccf7a1cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. SILVER CLEAN (NO NULLS)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_crew_clean\",\n",
    "    comment=\"Silver high-quality rows with NULLs replaced by meaningful defaults\",\n",
    "    table_properties={\n",
    "        \"quality\": \"silver_clean\",\n",
    "        \"pipelines.autoOptimize.zOrderCols\": \"TCONST\"\n",
    "    }\n",
    ")\n",
    "def silver_title_crew_clean():\n",
    "    \"\"\"\n",
    "    Silver Clean layer: Replace all NULLs with meaningful default values\n",
    "    Only includes records that passed quality checks\n",
    "    \"\"\"\n",
    "    df = dlt.read(\"silver_title_crew\").filter(col(\"silver_quality_check\") == \"PASSED\")\n",
    "\n",
    "    return df.select(\n",
    "        coalesce(col(\"tconst_clean\"), lit(\"UNKNOWN\")).alias(\"TCONST\"),\n",
    "        \n",
    "        # Replace NULL directors/writers with meaningful defaults\n",
    "        coalesce(col(\"directors\"), lit(\"No Director Information\")).alias(\"Directors\"),\n",
    "        coalesce(col(\"writers\"), lit(\"No Writer Information\")).alias(\"Writers\"),\n",
    "        \n",
    "        # Arrays and counts\n",
    "        coalesce(col(\"directors_array\"), expr(\"array()\")).alias(\"Directors_Array\"),\n",
    "        coalesce(col(\"writers_array\"), expr(\"array()\")).alias(\"Writers_Array\"),\n",
    "        coalesce(col(\"directors_count\"), lit(0)).alias(\"Directors_Count\"),\n",
    "        coalesce(col(\"writers_count\"), lit(0)).alias(\"Writers_Count\"),\n",
    "        \n",
    "        # Quality metrics\n",
    "        coalesce(col(\"data_completeness_score\"), lit(0)).alias(\"Data_Completeness_Score\"),\n",
    "        coalesce(col(\"quality_tier\"), lit(\"UNKNOWN\")).alias(\"Quality_Tier\"),\n",
    "        \n",
    "        # Flags for data presence\n",
    "        when(col(\"directors\").isNotNull(), lit(True)).otherwise(lit(False)).alias(\"Has_Directors\"),\n",
    "        when(col(\"writers\").isNotNull(), lit(True)).otherwise(lit(False)).alias(\"Has_Writers\"),\n",
    "        when(col(\"directors\").isNotNull() & col(\"writers\").isNotNull(), lit(True)).otherwise(lit(False)).alias(\"Has_Complete_Crew\"),\n",
    "        \n",
    "        # Metadata\n",
    "        coalesce(col(\"silver_processing_timestamp\"), current_timestamp()).alias(\"Silver_Processing_Timestamp\"),\n",
    "        coalesce(col(\"silver_processing_date\"), current_timestamp().cast(\"date\")).alias(\"Silver_Processing_Date\"),\n",
    "        coalesce(col(\"silver_version\"), lit(\"1.0\")).alias(\"Silver_Version\"),\n",
    "        \n",
    "        coalesce(col(\"bronze_ingestion_timestamp\"), current_timestamp()).alias(\"Bronze_Ingestion_Timestamp\"),\n",
    "        coalesce(col(\"bronze_ingestion_date\"), current_timestamp().cast(\"date\")).alias(\"Bronze_Ingestion_Date\"),\n",
    "        coalesce(col(\"bronze_source_system\"), lit(\"imdb\")).alias(\"Bronze_Source_System\"),\n",
    "        coalesce(col(\"bronze_source_file\"), lit(\"UNKNOWN_FILE\")).alias(\"Bronze_Source_File\"),\n",
    "        coalesce(col(\"bronze_record_hash\"), lit(\"\")).alias(\"Bronze_Record_Hash\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94437f6e-6eb1-4193-a489-60e86b768137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. QUARANTINE\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_crew_quarantine\",\n",
    "    comment=\"Records that failed Silver quality checks\",\n",
    "    table_properties={\n",
    "        \"quality\": \"quarantine\"\n",
    "    }\n",
    ")\n",
    "def silver_title_crew_quarantine():\n",
    "    \"\"\"\n",
    "    Quarantine layer: Capture all records that fail validation\n",
    "    \"\"\"\n",
    "    df = dlt.read(\"silver_title_crew\").filter(col(\"silver_quality_check\") == \"FAILED\")\n",
    "    \n",
    "    # Add quarantine reason\n",
    "    df = df.withColumn(\n",
    "        \"quarantine_reason\",\n",
    "        when(~col(\"tconst_valid\"), \"Invalid TCONST format\")\n",
    "        .when(col(\"quality_tier\") == \"LOW\", \"Low data completeness score\")\n",
    "        .otherwise(\"Unknown validation failure\")\n",
    "    )\n",
    "    \n",
    "    df = df.withColumn(\"quarantine_timestamp\", current_timestamp())\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Crew_Bronze_Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
