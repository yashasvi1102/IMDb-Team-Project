{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03ed4fc4-9990-406c-a02b-0bd7d256c54a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, trim, current_timestamp, lit, expr, md5, \n",
    "    coalesce, concat_ws, row_number\n",
    ")\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb8800a0-7f6e-480c-a98d-f2f08b259b21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. CONFIG\n",
    "# ============================================================\n",
    "\n",
    "RAW_DATA_PATH = \"/Volumes/workspace/imdb/imdb/title.episode.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df28c0a3-7879-4ed9-9c48-3f34089e6621",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. BRONZE LAYER\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_title_episode\",\n",
    "    comment=\"Bronze table for IMDb title.episode - raw data plus audit columns\",\n",
    "    table_properties={\n",
    "        \"quality\": \"bronze\",\n",
    "        \"pipelines.autoOptimize.zOrderCols\": \"tconst\"\n",
    "    }\n",
    ")\n",
    "def bronze_title_episode():\n",
    "    \"\"\"\n",
    "    Bronze layer: Raw data ingestion from title.episode.tsv\n",
    "    \"\"\"\n",
    "    df_raw = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .csv(RAW_DATA_PATH)\n",
    "    )\n",
    "\n",
    "    # Convert empty strings to NULL\n",
    "    df_raw = (\n",
    "        df_raw\n",
    "        .withColumn(\"tconst\", when(trim(col(\"tconst\")) == \"\", None).otherwise(col(\"tconst\")))\n",
    "        .withColumn(\"parentTconst\", when(trim(col(\"parentTconst\")) == \"\", None).otherwise(col(\"parentTconst\")))\n",
    "        .withColumn(\"seasonNumber\", when(trim(col(\"seasonNumber\")) == \"\", None).otherwise(col(\"seasonNumber\")))\n",
    "        .withColumn(\"episodeNumber\", when(trim(col(\"episodeNumber\")) == \"\", None).otherwise(col(\"episodeNumber\")))\n",
    "    )\n",
    "\n",
    "    df_bronze = (\n",
    "        df_raw\n",
    "        .withColumn(\"bronze_ingestion_timestamp\", current_timestamp())\n",
    "        .withColumn(\"bronze_ingestion_date\", current_timestamp().cast(\"date\"))\n",
    "        .withColumn(\"bronze_source_system\", lit(\"imdb\"))\n",
    "        .withColumn(\"bronze_source_file\", lit(RAW_DATA_PATH))\n",
    "        .withColumn(\n",
    "            \"bronze_record_hash\",\n",
    "            md5(\n",
    "                concat_ws(\n",
    "                    \"|\",\n",
    "                    coalesce(col(\"tconst\"), lit(\"\")),\n",
    "                    coalesce(col(\"parentTconst\"), lit(\"\")),\n",
    "                    coalesce(col(\"seasonNumber\"), lit(\"\")),\n",
    "                    coalesce(col(\"episodeNumber\"), lit(\"\"))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df_bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb449e36-d166-48b1-a123-ab60a92f7895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. CLEANING HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def validate_tconst(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Validate TCONST format\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"tconst_valid\",\n",
    "        when(col(\"tconst\").isNotNull() & col(\"tconst\").rlike(\"^tt[0-9]+$\"), True).otherwise(False)\n",
    "    )\n",
    "\n",
    "def validate_parent_tconst(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Validate Parent TCONST format\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"parent_tconst_valid\",\n",
    "        when(col(\"parentTconst\").isNotNull() & col(\"parentTconst\").rlike(\"^tt[0-9]+$\"), True).otherwise(False)\n",
    "    )\n",
    "\n",
    "def clean_tconst(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and standardize TCONST\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"tconst_clean\",\n",
    "        when(col(\"tconst\").isNotNull(), trim(col(\"tconst\"))).otherwise(None)\n",
    "    )\n",
    "\n",
    "def clean_parent_tconst(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and standardize Parent TCONST\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"parent_tconst_clean\",\n",
    "        when(col(\"parentTconst\").isNotNull(), trim(col(\"parentTconst\"))).otherwise(None)\n",
    "    )\n",
    "\n",
    "def clean_season_number(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and validate season number\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"season_number_clean\",\n",
    "        when(\n",
    "            col(\"seasonNumber\").isNotNull()\n",
    "            & col(\"seasonNumber\").rlike(\"^[0-9]+$\")\n",
    "            & (col(\"seasonNumber\").cast(IntegerType()) >= 0),\n",
    "            col(\"seasonNumber\").cast(IntegerType())\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "\n",
    "def clean_episode_number(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Clean and validate episode number\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"episode_number_clean\",\n",
    "        when(\n",
    "            col(\"episodeNumber\").isNotNull()\n",
    "            & col(\"episodeNumber\").rlike(\"^[0-9]+$\")\n",
    "            & (col(\"episodeNumber\").cast(IntegerType()) >= 1),\n",
    "            col(\"episodeNumber\").cast(IntegerType())\n",
    "        ).otherwise(None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c20c248-953e-4958-b9ea-68e1151d4a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. SILVER ALL (CLEANED + QUALITY FLAGS - ALL RECORDS)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_episode\",\n",
    "    comment=\"Silver cleaned table with quality scoring - includes ALL records with quality flags\",\n",
    "    table_properties={\n",
    "        \"quality\": \"silver\",\n",
    "        \"pipelines.autoOptimize.zOrderCols\": \"tconst\"\n",
    "    }\n",
    ")\n",
    "def silver_title_episode():\n",
    "    \"\"\"\n",
    "    Silver layer: Clean and validate data with quality scoring\n",
    "    ALL records are kept here with quality flags\n",
    "    NULLs are preserved - will be replaced in silver_clean\n",
    "    \"\"\"\n",
    "    df = dlt.read(\"bronze_title_episode\")\n",
    "\n",
    "    df = validate_tconst(df)\n",
    "    df = validate_parent_tconst(df)\n",
    "    df = clean_tconst(df)\n",
    "    df = clean_parent_tconst(df)\n",
    "    df = clean_season_number(df)\n",
    "    df = clean_episode_number(df)\n",
    "\n",
    "    # Quality flags\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_season\",\n",
    "        col(\"season_number_clean\").isNotNull()\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_episode\",\n",
    "        col(\"episode_number_clean\").isNotNull()\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"has_anomalous_season\",\n",
    "        (col(\"season_number_clean\") < 0) | (col(\"season_number_clean\") > 100)\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"has_anomalous_episode\",\n",
    "        (col(\"episode_number_clean\") < 1) | (col(\"episode_number_clean\") > 1000)\n",
    "    )\n",
    "\n",
    "    # Quality scoring\n",
    "    df = df.withColumn(\n",
    "        \"data_completeness_score\",\n",
    "        (\n",
    "            when(col(\"tconst_valid\"), 25).otherwise(0)\n",
    "            + when(col(\"parent_tconst_valid\"), 25).otherwise(0)\n",
    "            + when(col(\"has_valid_season\"), 25).otherwise(0)\n",
    "            + when(col(\"has_valid_episode\"), 25).otherwise(0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"quality_tier\",\n",
    "        when(col(\"data_completeness_score\") >= 75, \"HIGH\")\n",
    "        .when(col(\"data_completeness_score\") >= 50, \"MEDIUM\")\n",
    "        .otherwise(\"LOW\")\n",
    "    )\n",
    "\n",
    "    # Metadata\n",
    "    df = df.withColumn(\"silver_processing_timestamp\", current_timestamp())\n",
    "    df = df.withColumn(\"silver_processing_date\", current_timestamp().cast(\"date\"))\n",
    "    df = df.withColumn(\"silver_version\", lit(\"1.0\"))\n",
    "\n",
    "    # Quality check flag (but don't filter - keep all records)\n",
    "    df = df.withColumn(\n",
    "        \"silver_quality_check\",\n",
    "        when(~col(\"tconst_valid\"), \"FAILED\")\n",
    "        .when(~col(\"parent_tconst_valid\"), \"FAILED\")\n",
    "        .when(col(\"has_anomalous_season\"), \"FAILED\")\n",
    "        .when(col(\"has_anomalous_episode\"), \"FAILED\")\n",
    "        .when(col(\"quality_tier\") == \"LOW\", \"FAILED\")\n",
    "        .otherwise(\"PASSED\")\n",
    "    )\n",
    "\n",
    "    # Add failure reason for tracking\n",
    "    df = df.withColumn(\n",
    "        \"quality_issue_reason\",\n",
    "        when(~col(\"tconst_valid\"), \"Invalid TCONST format\")\n",
    "        .when(~col(\"parent_tconst_valid\"), \"Invalid Parent TCONST format\")\n",
    "        .when(col(\"has_anomalous_season\"), \"Anomalous season number\")\n",
    "        .when(col(\"has_anomalous_episode\"), \"Anomalous episode number\")\n",
    "        .when(col(\"quality_tier\") == \"LOW\", \"Low data completeness score\")\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "    # Deduplicate by tconst\n",
    "    w = Window.partitionBy(\"tconst\").orderBy(col(\"bronze_ingestion_timestamp\").desc())\n",
    "    df = df.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f707b79b-e4df-4806-8425-8019c8b0649b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. SILVER CLEAN (NO NULLS - HIGH QUALITY ONLY)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_title_episode_clean\",\n",
    "    comment=\"Silver with NULLs replaced by meaningful defaults - includes ALL records\",\n",
    "    table_properties={\n",
    "        \"quality\": \"silver_clean\",\n",
    "        \"pipelines.autoOptimize.zOrderCols\": \"TCONST\"\n",
    "    }\n",
    ")\n",
    "def silver_title_episode_clean():\n",
    "    \"\"\"\n",
    "    Silver Clean layer: Replace all NULLs with meaningful default values\n",
    "    Includes ALL records - both PASSED and FAILED\n",
    "    \"\"\"\n",
    "    df = dlt.read(\"silver_title_episode\")  # No filter - keep ALL records\n",
    "\n",
    "    return df.select(\n",
    "        coalesce(col(\"tconst_clean\"), col(\"tconst\"), lit(\"UNKNOWN\")).alias(\"TCONST\"),\n",
    "        coalesce(col(\"parent_tconst_clean\"), col(\"parentTconst\"), lit(\"UNKNOWN\")).alias(\"Parent_TCONST\"),\n",
    "        \n",
    "        # Replace NULL season/episode numbers with meaningful defaults\n",
    "        coalesce(col(\"season_number_clean\"), lit(-1)).alias(\"Season_Number\"),\n",
    "        coalesce(col(\"episode_number_clean\"), lit(-1)).alias(\"Episode_Number\"),\n",
    "        \n",
    "        # Quality metrics\n",
    "        coalesce(col(\"data_completeness_score\"), lit(0)).alias(\"Data_Completeness_Score\"),\n",
    "        coalesce(col(\"quality_tier\"), lit(\"UNKNOWN\")).alias(\"Quality_Tier\"),\n",
    "        coalesce(col(\"silver_quality_check\"), lit(\"UNKNOWN\")).alias(\"Quality_Check\"),\n",
    "        coalesce(col(\"quality_issue_reason\"), lit(\"None\")).alias(\"Quality_Issue_Reason\"),\n",
    "        \n",
    "        # Flags for data presence\n",
    "        coalesce(col(\"has_valid_season\"), lit(False)).alias(\"Has_Valid_Season\"),\n",
    "        coalesce(col(\"has_valid_episode\"), lit(False)).alias(\"Has_Valid_Episode\"),\n",
    "        coalesce(col(\"tconst_valid\"), lit(False)).alias(\"TCONST_Valid\"),\n",
    "        coalesce(col(\"parent_tconst_valid\"), lit(False)).alias(\"Parent_TCONST_Valid\"),\n",
    "        \n",
    "        # Metadata\n",
    "        coalesce(col(\"silver_processing_timestamp\"), current_timestamp()).alias(\"Silver_Processing_Timestamp\"),\n",
    "        coalesce(col(\"silver_processing_date\"), current_timestamp().cast(\"date\")).alias(\"Silver_Processing_Date\"),\n",
    "        coalesce(col(\"silver_version\"), lit(\"1.0\")).alias(\"Silver_Version\"),\n",
    "        \n",
    "        coalesce(col(\"bronze_ingestion_timestamp\"), current_timestamp()).alias(\"Bronze_Ingestion_Timestamp\"),\n",
    "        coalesce(col(\"bronze_ingestion_date\"), current_timestamp().cast(\"date\")).alias(\"Bronze_Ingestion_Date\"),\n",
    "        coalesce(col(\"bronze_source_system\"), lit(\"imdb\")).alias(\"Bronze_Source_System\"),\n",
    "        coalesce(col(\"bronze_source_file\"), lit(\"UNKNOWN_FILE\")).alias(\"Bronze_Source_File\"),\n",
    "        coalesce(col(\"bronze_record_hash\"), lit(\"\")).alias(\"Bronze_Record_Hash\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "episode_bronze_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
