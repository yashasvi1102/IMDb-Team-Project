{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51e6836d-28f0-4c6e-a86c-864ae52fe8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, regexp_replace, trim, split, array_distinct,\n",
    "    array_remove, size, concat_ws, current_timestamp,\n",
    "    lit, expr, md5, coalesce, lower, row_number\n",
    ")\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# ============================================================\n",
    "# 1. CONFIG\n",
    "# ============================================================\n",
    "\n",
    "RAW_DATA_PATH = \"/Volumes/workspace/imdb/imdb/title.akas.tsv\"\n",
    "LANGUAGE_CODES_PATH = \"/Volumes/workspace/imdb/imdb/language-codes-iso.tsv\"   # update path\n",
    "REGION_CODES_PATH   = \"/Volumes/workspace/imdb/imdb/countries_iso - all.tsv\"     # update path\n",
    "\n",
    "# ============================================================\n",
    "# 2. BRONZE LAYER\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_bronze\",\n",
    "    comment=\"Bronze table for IMDb title.akas – raw data plus audit columns\"\n",
    ")\n",
    "def title_akas_bronze():\n",
    "    df_raw = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"nullValue\", \"\\\\N\")\n",
    "        .csv(RAW_DATA_PATH)\n",
    "    )\n",
    "\n",
    "    # normalize empties to nulls\n",
    "    df_raw = (\n",
    "        df_raw\n",
    "        .withColumn(\"titleId\", when(trim(col(\"titleId\")) == \"\", None).otherwise(col(\"titleId\")))\n",
    "        .withColumn(\"ordering\", when(trim(col(\"ordering\")) == \"\", None).otherwise(col(\"ordering\")))\n",
    "        .withColumn(\"title\", when(trim(col(\"title\")) == \"\", None).otherwise(col(\"title\")))\n",
    "        .withColumn(\"region\", when(trim(col(\"region\")) == \"\", None).otherwise(col(\"region\")))\n",
    "        .withColumn(\"language\", when(trim(col(\"language\")) == \"\", None).otherwise(col(\"language\")))\n",
    "        .withColumn(\"types\", when(trim(col(\"types\")) == \"\", None).otherwise(col(\"types\")))\n",
    "        .withColumn(\"attributes\", when(trim(col(\"attributes\")) == \"\", None).otherwise(col(\"attributes\")))\n",
    "        .withColumn(\"isOriginalTitle\", when(trim(col(\"isOriginalTitle\")) == \"\", None).otherwise(col(\"isOriginalTitle\")))\n",
    "    )\n",
    "\n",
    "    df_bronze = (\n",
    "        df_raw\n",
    "        .withColumn(\"bronze_ingestion_timestamp\", current_timestamp())\n",
    "        .withColumn(\"bronze_ingestion_date\", current_timestamp().cast(\"date\"))\n",
    "        .withColumn(\"bronze_source_system\", lit(\"imdb\"))\n",
    "        .withColumn(\"bronze_source_file\", lit(RAW_DATA_PATH))\n",
    "        .withColumn(\n",
    "            \"bronze_record_hash\",\n",
    "            md5(\n",
    "                concat_ws(\n",
    "                    \"|\",\n",
    "                    coalesce(col(\"titleId\"), lit(\"\")),\n",
    "                    coalesce(col(\"ordering\"), lit(\"\")),\n",
    "                    coalesce(col(\"title\"), lit(\"\")),\n",
    "                    coalesce(col(\"region\"), lit(\"\")),\n",
    "                    coalesce(col(\"language\"), lit(\"\")),\n",
    "                    coalesce(col(\"types\"), lit(\"\")),\n",
    "                    coalesce(col(\"attributes\"), lit(\"\")),\n",
    "                    coalesce(col(\"isOriginalTitle\"), lit(\"\"))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df_bronze\n",
    "\n",
    "# ============================================================\n",
    "# 3. CLEANING HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def validate_title_id(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Flag whether titleId is a valid IMDb title id (tt[0-9]+).\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"titleId_valid\",\n",
    "        when(col(\"titleId\").isNotNull() & col(\"titleId\").rlike(\"^tt[0-9]+$\"), True).otherwise(False)\n",
    "    )\n",
    "\n",
    "def clean_ordering(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Parse ordering as positive integer; leave NULL if bad.\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"ordering_clean\",\n",
    "        when(\n",
    "            col(\"ordering\").isNotNull() &\n",
    "            col(\"ordering\").rlike(\"^[0-9]+$\") &\n",
    "            (col(\"ordering\").cast(IntegerType()) >= 1) &\n",
    "            (col(\"ordering\").cast(IntegerType()) <= 100000),\n",
    "            col(\"ordering\").cast(IntegerType())\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "\n",
    "def clean_title(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Normalize alternative title.\"\"\"\n",
    "    return df.withColumn(\n",
    "        \"title_clean\",\n",
    "        when(col(\"title\").isNotNull(),\n",
    "             trim(regexp_replace(col(\"title\"), \"\\\\s+\", \" \")))\n",
    "    )\n",
    "\n",
    "def clean_region_language(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Normalize region and language codes to lower-case; drop weird junk.\"\"\"\n",
    "    df = df.withColumn(\n",
    "        \"region_clean\",\n",
    "        when(col(\"region\").isNotNull(),\n",
    "             lower(trim(col(\"region\"))))\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"language_clean\",\n",
    "        when(col(\"language\").isNotNull(),\n",
    "             lower(trim(col(\"language\"))))\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def parse_types_attributes(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"Split comma-separated types/attributes into arrays.\"\"\"\n",
    "    df = df.withColumn(\n",
    "        \"types_array\",\n",
    "        when(col(\"types\").isNotNull(),\n",
    "             array_distinct(array_remove(split(col(\"types\"), \",\"), \"\")))\n",
    "        .otherwise(expr(\"array()\"))\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"attributes_array\",\n",
    "        when(col(\"attributes\").isNotNull(),\n",
    "             array_distinct(array_remove(split(col(\"attributes\"), \",\"), \"\")))\n",
    "        .otherwise(expr(\"array()\"))\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\"types_count\", size(col(\"types_array\")))\n",
    "    df = df.withColumn(\"attributes_count\", size(col(\"attributes_array\")))\n",
    "    return df\n",
    "\n",
    "def clean_is_original(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Convert isOriginalTitle from string to boolean:\n",
    "      '1' -> True\n",
    "      '0' or NULL -> False (but we still track validity separately)\n",
    "    \"\"\"\n",
    "    df = df.withColumn(\n",
    "        \"is_original_flag\",\n",
    "        when(col(\"isOriginalTitle\") == \"1\", True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# 4. SILVER ALL (CLEANED + QUALITY FLAGS)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_silver_all\",\n",
    "    comment=\"Silver cleaned table for title.akas with quality scoring\"\n",
    ")\n",
    "def title_akas_silver_all():\n",
    "\n",
    "    df = dlt.read(\"title_akas_bronze\")\n",
    "\n",
    "    # Cleaning\n",
    "    df = validate_title_id(df)\n",
    "    df = clean_ordering(df)\n",
    "    df = clean_title(df)\n",
    "    df = clean_region_language(df)\n",
    "    df = parse_types_attributes(df)\n",
    "    df = clean_is_original(df)\n",
    "\n",
    "    # ===========================\n",
    "    # VALIDITY FLAGS\n",
    "    # ===========================\n",
    "\n",
    "    # Ordering:\n",
    "    #   - NULL original is OK (unknown)\n",
    "    #   - non-null must parse and be > 0 and within sane limit\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_ordering\",\n",
    "        when(col(\"ordering\").isNull(), True)\n",
    "        .when(col(\"ordering_clean\").isNotNull(), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "    # Region:\n",
    "    #   - NULL original is OK\n",
    "    #   - non-null must have a cleaned value (simple a-z0-9/- like codes)\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_region\",\n",
    "        when(col(\"region\").isNull(), True)\n",
    "        .when(col(\"region_clean\").isNotNull(), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "    # Language:\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_language\",\n",
    "        when(col(\"language\").isNull(), True)\n",
    "        .when(col(\"language_clean\").isNotNull(), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "    # isOriginalTitle:\n",
    "    #   allowed values: NULL, '0', '1'\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_is_original\",\n",
    "        when(col(\"isOriginalTitle\").isNull(), True)\n",
    "        .when(col(\"isOriginalTitle\").isin(\"0\", \"1\"), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "    # Completeness score (for information only)\n",
    "    df = df.withColumn(\n",
    "        \"data_completeness_score\",\n",
    "        (\n",
    "            when(col(\"titleId_valid\"), 20).otherwise(0)\n",
    "            + when(col(\"title_clean\").isNotNull(), 20).otherwise(0)\n",
    "            + when(col(\"ordering_clean\").isNotNull(), 20).otherwise(0)\n",
    "            + when(col(\"region_clean\").isNotNull(), 20).otherwise(0)\n",
    "            + when(col(\"language_clean\").isNotNull(), 20).otherwise(0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"quality_tier\",\n",
    "        when(col(\"data_completeness_score\") >= 80, \"HIGH\")\n",
    "        .when(col(\"data_completeness_score\") >= 60, \"MEDIUM\")\n",
    "        .when(col(\"data_completeness_score\") >= 40, \"LOW\")\n",
    "        .otherwise(\"POOR\")\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\"silver_processing_timestamp\", current_timestamp())\n",
    "    df = df.withColumn(\"silver_processing_date\", current_timestamp().cast(\"date\"))\n",
    "    df = df.withColumn(\"silver_version\", lit(\"1.0\"))\n",
    "\n",
    "    # FINAL QUALITY DECISION – quarantine ONLY truly bad rows\n",
    "    df = df.withColumn(\n",
    "        \"silver_quality_check\",\n",
    "        when(~col(\"titleId_valid\"), \"FAILED\")\n",
    "        .when(~col(\"has_valid_ordering\"), \"FAILED\")\n",
    "        .when(~col(\"has_valid_region\"), \"FAILED\")\n",
    "        .when(~col(\"has_valid_language\"), \"FAILED\")\n",
    "        .when(~col(\"has_valid_is_original\"), \"FAILED\")\n",
    "        .otherwise(\"PASSED\")\n",
    "    )\n",
    "\n",
    "    # Deduplicate by (titleId, ordering), keep latest ingestion\n",
    "    w = Window.partitionBy(\"titleId\", \"ordering\").orderBy(col(\"bronze_ingestion_timestamp\").desc())\n",
    "    df = df.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# 5. SILVER CLEAN (NO NULLS, READY FOR GOLD)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_silver_clean\",\n",
    "    comment=\"High-quality Silver records for title.akas (with region & language names, no NULLs in key fields)\"\n",
    ")\n",
    "def title_akas_silver_clean():\n",
    "    # 1) Start from Silver_all and keep only PASSED rows\n",
    "    df = dlt.read(\"title_akas_silver_all\").filter(col(\"silver_quality_check\") == \"PASSED\")\n",
    "\n",
    "    # 2) Read language and region lookup TSVs\n",
    "    # --- Language mapping (ISO codes) ---\n",
    "    lang_ref_raw = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .csv(LANGUAGE_CODES_PATH)\n",
    "    )\n",
    "\n",
    "    language_ref = lang_ref_raw.select(\n",
    "        lower(trim(col(\"alpha2\"))).alias(\"ref_language_code\"),\n",
    "        col(\"English\").alias(\"language_name\")\n",
    "    )\n",
    "\n",
    "    # --- Region mapping (country codes) ---\n",
    "    region_ref_raw = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .csv(REGION_CODES_PATH)\n",
    "    )\n",
    "\n",
    "    region_ref = region_ref_raw.select(\n",
    "        lower(trim(col(\"alpha-2\"))).alias(\"ref_region_code\"),\n",
    "        col(\"name\").alias(\"region_name\")\n",
    "    )\n",
    "\n",
    "    # 3) Join Silver data with reference data (left joins so we don't lose rows)\n",
    "    df = (\n",
    "        df\n",
    "        .join(region_ref, df.region_clean == region_ref.ref_region_code, \"left\")\n",
    "        .join(language_ref, df.language_clean == language_ref.ref_language_code, \"left\")\n",
    "    )\n",
    "\n",
    "    # 4) Select final columns (codes + full names + lineage)\n",
    "    return df.select(\n",
    "        # IDs / keys\n",
    "        coalesce(col(\"titleId\"), lit(\"UNKNOWN\")).alias(\"title_imdb_id\"),\n",
    "        coalesce(col(\"ordering_clean\"), lit(0)).alias(\"ordering\"),\n",
    "\n",
    "        # Titles\n",
    "        coalesce(col(\"title_clean\"), lit(\"Unknown\")).alias(\"aka_title\"),\n",
    "\n",
    "        # Region: code from akas + full name from region TSV\n",
    "        coalesce(col(\"region_clean\"), lit(\"unknown\")).alias(\"region_code\"),\n",
    "        coalesce(col(\"region_name\"), lit(\"Unknown Region\")).alias(\"region_name\"),\n",
    "\n",
    "        # Language: code from akas + full name from language TSV\n",
    "        coalesce(col(\"language_clean\"), lit(\"unknown\")).alias(\"language_code\"),\n",
    "        coalesce(col(\"language_name\"), lit(\"Unknown Language\")).alias(\"language_name\"),\n",
    "\n",
    "        # Types / attributes as arrays\n",
    "        coalesce(col(\"types_array\"), expr(\"array()\")).alias(\"types\"),\n",
    "        coalesce(col(\"attributes_array\"), expr(\"array()\")).alias(\"attributes\"),\n",
    "        coalesce(col(\"types_count\"), lit(0)).alias(\"types_count\"),\n",
    "        coalesce(col(\"attributes_count\"), lit(0)).alias(\"attributes_count\"),\n",
    "\n",
    "        # Original title flag\n",
    "        coalesce(col(\"is_original_flag\"), lit(False)).alias(\"is_original_title\"),\n",
    "\n",
    "        # Completeness / quality\n",
    "        coalesce(col(\"data_completeness_score\"), lit(0)).alias(\"data_completeness_score\"),\n",
    "        coalesce(col(\"quality_tier\"), lit(\"UNKNOWN\")).alias(\"quality_tier\"),\n",
    "\n",
    "        # Audit / lineage\n",
    "        coalesce(col(\"silver_processing_timestamp\"), current_timestamp()).alias(\"silver_processing_timestamp\"),\n",
    "        coalesce(col(\"silver_processing_date\"), current_timestamp().cast(\"date\")).alias(\"silver_processing_date\"),\n",
    "        coalesce(col(\"silver_version\"), lit(\"1.0\")).alias(\"silver_version\"),\n",
    "\n",
    "        coalesce(col(\"bronze_ingestion_timestamp\"), current_timestamp()).alias(\"bronze_ingestion_timestamp\"),\n",
    "        coalesce(col(\"bronze_ingestion_date\"), current_timestamp().cast(\"date\")).alias(\"bronze_ingestion_date\"),\n",
    "\n",
    "        coalesce(col(\"bronze_source_system\"), lit(\"imdb\")).alias(\"bronze_source_system\"),\n",
    "        coalesce(col(\"bronze_source_file\"), lit(\"UNKNOWN_FILE\")).alias(\"bronze_source_file\"),\n",
    "        coalesce(col(\"bronze_record_hash\"), lit(\"\")).alias(\"bronze_record_hash\")\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# 6. QUARANTINE\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_quarantine\",\n",
    "    comment=\"Records from title.akas that failed Silver quality checks (invalid IDs, codes, ordering)\"\n",
    ")\n",
    "def title_akas_quarantine():\n",
    "    return dlt.read(\"title_akas_silver_all\").filter(col(\"silver_quality_check\") == \"FAILED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8ba46a5-4418-456a-a496-8163f9fbd368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "import dlt\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, regexp_replace, trim, split, array_distinct,\n",
    "    array_remove, size, concat_ws, current_timestamp,\n",
    "    lit, expr, md5, coalesce, lower, row_number, array_contains,\n",
    "    arrays_overlap, array\n",
    ")\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# ============================================================\n",
    "# 1. CONFIG\n",
    "# ============================================================\n",
    "\n",
    "RAW_DATA_PATH = \"/Volumes/workspace/damg7370/datastore/imdb/raw/title.akas.tsv\"\n",
    "\n",
    "# ============================================================\n",
    "# 2. REFERENCE DATA - Based on Official IMDb and ISO Standards\n",
    "# ============================================================\n",
    "\n",
    "# Valid IMDb types for title.akas (from IMDb documentation)\n",
    "# Source: https://developer.imdb.com/non-commercial-datasets/\n",
    "VALID_TYPES = [\n",
    "    \"alternative\",\n",
    "    \"dvd\",\n",
    "    \"festival\",\n",
    "    \"tv\",\n",
    "    \"video\",\n",
    "    \"working\",\n",
    "    \"original\",\n",
    "    \"imdbDisplay\"\n",
    "]\n",
    "\n",
    "# Valid region codes (ISO 3166-1 alpha-2 + IMDb historical codes)\n",
    "# Source: https://help.imdb.com/article/contribution/other-submission-guides/country-codes/G99K4LFRMSC37DCN\n",
    "VALID_REGION_CODES = [\n",
    "    # Standard ISO 3166-1 alpha-2 codes (lowercase)\n",
    "    \"af\", \"ax\", \"al\", \"dz\", \"as\", \"ad\", \"ao\", \"ai\", \"aq\", \"ag\", \"ar\", \"am\", \"aw\", \"au\", \"at\", \"az\",\n",
    "    \"bs\", \"bh\", \"bd\", \"bb\", \"by\", \"be\", \"bz\", \"bj\", \"bm\", \"bt\", \"bo\", \"ba\", \"bw\", \"bv\", \"br\", \"io\",\n",
    "    \"vg\", \"bn\", \"bg\", \"bf\", \"bi\", \"kh\", \"cm\", \"ca\", \"cv\", \"ky\", \"cf\", \"td\", \"cl\", \"cn\", \"cx\", \"cc\",\n",
    "    \"co\", \"km\", \"cg\", \"cd\", \"ck\", \"cr\", \"ci\", \"hr\", \"cu\", \"cy\", \"cz\", \"dk\", \"dj\", \"dm\", \"do\", \"ec\",\n",
    "    \"eg\", \"sv\", \"gq\", \"er\", \"ee\", \"et\", \"fk\", \"fo\", \"fj\", \"fi\", \"fr\", \"gf\", \"pf\", \"tf\", \"ga\", \"gm\",\n",
    "    \"ge\", \"de\", \"gh\", \"gi\", \"gb\", \"gr\", \"gl\", \"gd\", \"gp\", \"gu\", \"gt\", \"gg\", \"gw\", \"gn\", \"gy\", \"ht\",\n",
    "    \"hm\", \"hn\", \"hk\", \"hu\", \"is\", \"in\", \"id\", \"ir\", \"iq\", \"ie\", \"im\", \"il\", \"it\", \"jm\", \"jp\", \"je\",\n",
    "    \"jo\", \"kz\", \"ke\", \"ki\", \"kp\", \"kr\", \"kw\", \"kg\", \"la\", \"lv\", \"lb\", \"ls\", \"lr\", \"ly\", \"li\", \"lt\",\n",
    "    \"lu\", \"mo\", \"mg\", \"mw\", \"my\", \"mv\", \"ml\", \"mt\", \"mh\", \"mq\", \"mr\", \"mu\", \"yt\", \"mx\", \"fm\", \"md\",\n",
    "    \"mc\", \"mn\", \"me\", \"ms\", \"ma\", \"mz\", \"mm\", \"na\", \"nr\", \"np\", \"an\", \"nl\", \"nc\", \"nz\", \"ni\", \"ne\",\n",
    "    \"ng\", \"nu\", \"nf\", \"mk\", \"mp\", \"no\", \"om\", \"pk\", \"pw\", \"ps\", \"pa\", \"pg\", \"py\", \"pe\", \"ph\", \"pn\",\n",
    "    \"pl\", \"pt\", \"pr\", \"qa\", \"re\", \"ro\", \"ru\", \"rw\", \"sh\", \"kn\", \"lc\", \"pm\", \"vc\", \"ws\", \"sm\", \"st\",\n",
    "    \"sa\", \"sn\", \"rs\", \"sc\", \"sl\", \"sg\", \"sk\", \"si\", \"sb\", \"so\", \"za\", \"gs\", \"es\", \"lk\", \"sd\", \"sr\",\n",
    "    \"sj\", \"sz\", \"se\", \"ch\", \"sy\", \"tw\", \"tj\", \"tz\", \"th\", \"tl\", \"tg\", \"tk\", \"to\", \"tt\", \"tn\", \"tr\",\n",
    "    \"tm\", \"tc\", \"tv\", \"ug\", \"ua\", \"ae\", \"um\", \"vi\", \"us\", \"uy\", \"uz\", \"vu\", \"va\", \"ve\", \"vn\", \"wf\",\n",
    "    \"eh\", \"ye\", \"zm\", \"zw\",\n",
    "    # Kosovo (special IMDb code)\n",
    "    \"xkv\",\n",
    "    # Historical country codes (from IMDb documentation)\n",
    "    \"cshh\",  # Czechoslovakia\n",
    "    \"csxx\",  # Serbia and Montenegro\n",
    "    \"ddde\",  # German Democratic Republic (East Germany)\n",
    "    \"suhh\",  # Soviet Union (USSR)\n",
    "    \"yucs\",  # Yugoslavia\n",
    "    # Additional codes that may appear in IMDb data\n",
    "    \"xww\",   # Worldwide\n",
    "    \"xeu\",   # Europe\n",
    "    \"xas\",   # Asia\n",
    "    \"xna\",   # North America\n",
    "    \"xsa\",   # South America\n",
    "    \"xoc\",   # Oceania\n",
    "    \"xaf\",   # Africa\n",
    "]\n",
    "\n",
    "# Valid language codes (ISO 639-1 two-letter codes)\n",
    "# Source: https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes\n",
    "VALID_LANGUAGE_CODES = [\n",
    "    \"ab\", \"aa\", \"af\", \"ak\", \"sq\", \"am\", \"ar\", \"an\", \"hy\", \"as\", \"av\", \"ae\", \"ay\", \"az\",\n",
    "    \"bm\", \"ba\", \"eu\", \"be\", \"bn\", \"bi\", \"bs\", \"br\", \"bg\", \"my\", \"ca\", \"ch\", \"ce\", \"ny\",\n",
    "    \"zh\", \"cu\", \"cv\", \"kw\", \"co\", \"cr\", \"hr\", \"cs\", \"da\", \"dv\", \"nl\", \"dz\", \"en\", \"eo\",\n",
    "    \"et\", \"ee\", \"fo\", \"fj\", \"fi\", \"fr\", \"fy\", \"ff\", \"gd\", \"gl\", \"lg\", \"ka\", \"de\", \"el\",\n",
    "    \"kl\", \"gn\", \"gu\", \"ht\", \"ha\", \"he\", \"hz\", \"hi\", \"ho\", \"hu\", \"is\", \"io\", \"ig\", \"id\",\n",
    "    \"ia\", \"ie\", \"iu\", \"ik\", \"ga\", \"it\", \"ja\", \"jv\", \"kn\", \"kr\", \"ks\", \"kk\", \"km\", \"ki\",\n",
    "    \"rw\", \"ky\", \"kv\", \"kg\", \"ko\", \"kj\", \"ku\", \"lo\", \"la\", \"lv\", \"li\", \"ln\", \"lt\", \"lu\",\n",
    "    \"lb\", \"mk\", \"mg\", \"ms\", \"ml\", \"mt\", \"gv\", \"mi\", \"mr\", \"mh\", \"mn\", \"na\", \"nv\", \"nd\",\n",
    "    \"nr\", \"ng\", \"ne\", \"no\", \"nb\", \"nn\", \"oc\", \"oj\", \"or\", \"om\", \"os\", \"pi\", \"ps\", \"fa\",\n",
    "    \"pl\", \"pt\", \"pa\", \"qu\", \"ro\", \"rm\", \"rn\", \"ru\", \"se\", \"sm\", \"sg\", \"sa\", \"sc\", \"sr\",\n",
    "    \"sn\", \"sd\", \"si\", \"sk\", \"sl\", \"so\", \"st\", \"es\", \"su\", \"sw\", \"ss\", \"sv\", \"tl\", \"ty\",\n",
    "    \"tg\", \"ta\", \"tt\", \"te\", \"th\", \"bo\", \"ti\", \"to\", \"ts\", \"tn\", \"tr\", \"tk\", \"tw\", \"ug\",\n",
    "    \"uk\", \"ur\", \"uz\", \"ve\", \"vi\", \"vo\", \"wa\", \"cy\", \"wo\", \"xh\", \"ii\", \"yi\", \"yo\", \"za\", \"zu\",\n",
    "    # Additional common codes found in IMDb data\n",
    "    \"cmn\",  # Mandarin Chinese (ISO 639-3)\n",
    "    \"yue\",  # Cantonese (ISO 639-3)\n",
    "    \"qbn\",  # Bengali variant\n",
    "    \"qbo\",  # Tibetan variant\n",
    "    \"qbp\",  # Some IMDb-specific codes\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 3. BRONZE LAYER\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_bronze\",\n",
    "    comment=\"Bronze table for IMDb title.akas – raw data plus audit columns. Source: https://datasets.imdbws.com/\"\n",
    ")\n",
    "def title_akas_bronze():\n",
    "    \"\"\"\n",
    "    Ingests raw IMDb title.akas.tsv data with minimal transformations.\n",
    "    \n",
    "    Schema per IMDb documentation (https://developer.imdb.com/non-commercial-datasets/):\n",
    "    - titleId: tconst (alphanumeric unique identifier, format: tt[0-9]+)\n",
    "    - ordering: integer to uniquely identify rows for a given titleId\n",
    "    - title: localized title\n",
    "    - region: region code for this version (ISO 3166-1 alpha-2)\n",
    "    - language: language code (ISO 639-1)\n",
    "    - types: enumerated attributes (alternative, dvd, festival, tv, video, working, original, imdbDisplay)\n",
    "    - attributes: additional descriptive terms (not enumerated)\n",
    "    - isOriginalTitle: 0 or 1 boolean\n",
    "    \"\"\"\n",
    "    df_raw = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"sep\", \"\\t\")\n",
    "        .option(\"nullValue\", \"\\\\N\")  # IMDb uses \\N for NULL values\n",
    "        .csv(RAW_DATA_PATH)\n",
    "    )\n",
    "\n",
    "    # Normalize empty strings to nulls (consistent with \\N handling)\n",
    "    df_raw = (\n",
    "        df_raw\n",
    "        .withColumn(\"titleId\", when(trim(col(\"titleId\")) == \"\", None).otherwise(col(\"titleId\")))\n",
    "        .withColumn(\"ordering\", when(trim(col(\"ordering\")) == \"\", None).otherwise(col(\"ordering\")))\n",
    "        .withColumn(\"title\", when(trim(col(\"title\")) == \"\", None).otherwise(col(\"title\")))\n",
    "        .withColumn(\"region\", when(trim(col(\"region\")) == \"\", None).otherwise(col(\"region\")))\n",
    "        .withColumn(\"language\", when(trim(col(\"language\")) == \"\", None).otherwise(col(\"language\")))\n",
    "        .withColumn(\"types\", when(trim(col(\"types\")) == \"\", None).otherwise(col(\"types\")))\n",
    "        .withColumn(\"attributes\", when(trim(col(\"attributes\")) == \"\", None).otherwise(col(\"attributes\")))\n",
    "        .withColumn(\"isOriginalTitle\", when(trim(col(\"isOriginalTitle\")) == \"\", None).otherwise(col(\"isOriginalTitle\")))\n",
    "    )\n",
    "\n",
    "    # Add audit/lineage columns\n",
    "    df_bronze = (\n",
    "        df_raw\n",
    "        .withColumn(\"bronze_ingestion_timestamp\", current_timestamp())\n",
    "        .withColumn(\"bronze_ingestion_date\", current_timestamp().cast(\"date\"))\n",
    "        .withColumn(\"bronze_source_system\", lit(\"imdb\"))\n",
    "        .withColumn(\"bronze_source_file\", lit(RAW_DATA_PATH))\n",
    "        .withColumn(\n",
    "            \"bronze_record_hash\",\n",
    "            md5(\n",
    "                concat_ws(\n",
    "                    \"|\",\n",
    "                    coalesce(col(\"titleId\"), lit(\"\")),\n",
    "                    coalesce(col(\"ordering\"), lit(\"\")),\n",
    "                    coalesce(col(\"title\"), lit(\"\")),\n",
    "                    coalesce(col(\"region\"), lit(\"\")),\n",
    "                    coalesce(col(\"language\"), lit(\"\")),\n",
    "                    coalesce(col(\"types\"), lit(\"\")),\n",
    "                    coalesce(col(\"attributes\"), lit(\"\")),\n",
    "                    coalesce(col(\"isOriginalTitle\"), lit(\"\"))\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df_bronze\n",
    "\n",
    "# ============================================================\n",
    "# 4. CLEANING HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def validate_title_id(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Validate titleId follows IMDb tconst format: tt followed by digits.\n",
    "    Per IMDb docs: \"a tconst, an alphanumeric unique identifier of the title\"\n",
    "    \"\"\"\n",
    "    return df.withColumn(\n",
    "        \"titleId_valid\",\n",
    "        when(\n",
    "            col(\"titleId\").isNotNull() & \n",
    "            col(\"titleId\").rlike(\"^tt[0-9]+$\"), \n",
    "            True\n",
    "        ).otherwise(False)\n",
    "    )\n",
    "\n",
    "def clean_ordering(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Parse ordering as positive integer.\n",
    "    Per IMDb docs: \"a number to uniquely identify rows for a given titleId\"\n",
    "    Ordering starts from 1 and should be reasonable (cap at 100000 for sanity).\n",
    "    \"\"\"\n",
    "    return df.withColumn(\n",
    "        \"ordering_clean\",\n",
    "        when(\n",
    "            col(\"ordering\").isNotNull() &\n",
    "            col(\"ordering\").rlike(\"^[0-9]+$\") &\n",
    "            (col(\"ordering\").cast(IntegerType()) >= 1) &\n",
    "            (col(\"ordering\").cast(IntegerType()) <= 100000),\n",
    "            col(\"ordering\").cast(IntegerType())\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "\n",
    "def clean_title(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize alternative title: trim whitespace and collapse multiple spaces.\n",
    "    Per IMDb docs: \"the localized title\"\n",
    "    \"\"\"\n",
    "    return df.withColumn(\n",
    "        \"title_clean\",\n",
    "        when(\n",
    "            col(\"title\").isNotNull(),\n",
    "            trim(regexp_replace(col(\"title\"), \"\\\\s+\", \" \"))\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "\n",
    "def clean_region(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize and validate region codes.\n",
    "    Per IMDb docs: \"the region for this version of the title\"\n",
    "    Uses ISO 3166-1 alpha-2 codes plus IMDb historical codes.\n",
    "    \"\"\"\n",
    "    # Create array of valid region codes for comparison\n",
    "    valid_regions_array = array(*[lit(code) for code in VALID_REGION_CODES])\n",
    "    \n",
    "    df = df.withColumn(\n",
    "        \"region_clean\",\n",
    "        when(col(\"region\").isNotNull(), lower(trim(col(\"region\")))).otherwise(None)\n",
    "    )\n",
    "    \n",
    "    # Validate against known codes\n",
    "    df = df.withColumn(\n",
    "        \"region_is_valid_code\",\n",
    "        when(col(\"region_clean\").isNull(), True)  # NULL is acceptable\n",
    "        .when(array_contains(valid_regions_array, col(\"region_clean\")), True)\n",
    "        # Also accept 2-4 character alphanumeric codes (for flexibility with new/unknown codes)\n",
    "        .when(col(\"region_clean\").rlike(\"^[a-z]{2,4}$\"), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_language(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize and validate language codes.\n",
    "    Per IMDb docs: \"the language of the title\"\n",
    "    Uses ISO 639-1 (2-letter) and some ISO 639-3 (3-letter) codes.\n",
    "    \"\"\"\n",
    "    # Create array of valid language codes for comparison\n",
    "    valid_languages_array = array(*[lit(code) for code in VALID_LANGUAGE_CODES])\n",
    "    \n",
    "    df = df.withColumn(\n",
    "        \"language_clean\",\n",
    "        when(col(\"language\").isNotNull(), lower(trim(col(\"language\")))).otherwise(None)\n",
    "    )\n",
    "    \n",
    "    # Validate against known codes\n",
    "    df = df.withColumn(\n",
    "        \"language_is_valid_code\",\n",
    "        when(col(\"language_clean\").isNull(), True)  # NULL is acceptable\n",
    "        .when(array_contains(valid_languages_array, col(\"language_clean\")), True)\n",
    "        # Also accept 2-3 character alphabetic codes (for flexibility)\n",
    "        .when(col(\"language_clean\").rlike(\"^[a-z]{2,3}$\"), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_types(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Parse and validate types field.\n",
    "    Per IMDb docs: \"Enumerated set of attributes for this alternative title. \n",
    "    One or more of: alternative, dvd, festival, tv, video, working, original, imdbDisplay\"\n",
    "    \"\"\"\n",
    "    # Create array of valid types for comparison\n",
    "    valid_types_array = array(*[lit(t) for t in VALID_TYPES])\n",
    "    \n",
    "    # Split comma-separated types into array\n",
    "    df = df.withColumn(\n",
    "        \"types_array\",\n",
    "        when(\n",
    "            col(\"types\").isNotNull(),\n",
    "            array_distinct(array_remove(split(col(\"types\"), \",\"), \"\"))\n",
    "        ).otherwise(expr(\"array()\"))\n",
    "    )\n",
    "    \n",
    "    df = df.withColumn(\"types_count\", size(col(\"types_array\")))\n",
    "    \n",
    "    # Check if all types are valid enumerated values\n",
    "    df = df.withColumn(\n",
    "        \"types_all_valid\",\n",
    "        when(\n",
    "            col(\"types\").isNull() | (size(col(\"types_array\")) == 0), \n",
    "            True\n",
    "        ).otherwise(\n",
    "            # All elements must be in valid types list\n",
    "            size(array_distinct(\n",
    "                expr(f\"filter(types_array, x -> array_contains(array{tuple(VALID_TYPES)}, x))\")\n",
    "            )) == size(col(\"types_array\"))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_attributes(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Parse attributes field.\n",
    "    Per IMDb docs: \"Additional terms to describe this alternative title, not enumerated\"\n",
    "    Since not enumerated, we just clean and split without validation.\n",
    "    \"\"\"\n",
    "    df = df.withColumn(\n",
    "        \"attributes_array\",\n",
    "        when(\n",
    "            col(\"attributes\").isNotNull(),\n",
    "            array_distinct(array_remove(split(col(\"attributes\"), \",\"), \"\"))\n",
    "        ).otherwise(expr(\"array()\"))\n",
    "    )\n",
    "    \n",
    "    df = df.withColumn(\"attributes_count\", size(col(\"attributes_array\")))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_is_original(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Convert isOriginalTitle from string to boolean.\n",
    "    Per IMDb docs: \"0: not original title; 1: original title\"\n",
    "    \"\"\"\n",
    "    df = df.withColumn(\n",
    "        \"is_original_flag\",\n",
    "        when(col(\"isOriginalTitle\") == \"1\", True)\n",
    "        .when(col(\"isOriginalTitle\") == \"0\", False)\n",
    "        .otherwise(None)  # NULL if invalid value\n",
    "    )\n",
    "    \n",
    "    # Validate that value is 0, 1, or NULL\n",
    "    df = df.withColumn(\n",
    "        \"is_original_valid\",\n",
    "        when(col(\"isOriginalTitle\").isNull(), True)\n",
    "        .when(col(\"isOriginalTitle\").isin(\"0\", \"1\"), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# 5. SILVER ALL (CLEANED + QUALITY FLAGS)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_silver_all\",\n",
    "    comment=\"Silver cleaned table for title.akas with comprehensive quality scoring based on IMDb standards\"\n",
    ")\n",
    "def title_akas_silver_all():\n",
    "    \"\"\"\n",
    "    Apply all cleaning transformations and generate quality metrics.\n",
    "    Records are flagged but not filtered - quarantine table handles bad records.\n",
    "    \"\"\"\n",
    "    df = dlt.read(\"title_akas_bronze\")\n",
    "\n",
    "    # Apply all cleaning functions\n",
    "    df = validate_title_id(df)\n",
    "    df = clean_ordering(df)\n",
    "    df = clean_title(df)\n",
    "    df = clean_region(df)\n",
    "    df = clean_language(df)\n",
    "    df = parse_types(df)\n",
    "    df = parse_attributes(df)\n",
    "    df = clean_is_original(df)\n",
    "\n",
    "    # ===========================\n",
    "    # VALIDITY FLAGS\n",
    "    # ===========================\n",
    "\n",
    "    # Ordering validation: NULL is OK, non-null must parse successfully\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_ordering\",\n",
    "        when(col(\"ordering\").isNull(), True)\n",
    "        .when(col(\"ordering_clean\").isNotNull(), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "    # Region validation: NULL is OK, non-null must be valid code\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_region\",\n",
    "        when(col(\"region\").isNull(), True)\n",
    "        .when(col(\"region_is_valid_code\"), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "    # Language validation: NULL is OK, non-null must be valid code\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_language\",\n",
    "        when(col(\"language\").isNull(), True)\n",
    "        .when(col(\"language_is_valid_code\"), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "    # Types validation: NULL is OK, non-null must have all valid enumerated values\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_types\",\n",
    "        when(col(\"types\").isNull(), True)\n",
    "        .when(col(\"types_all_valid\"), True)\n",
    "        .otherwise(False)\n",
    "    )\n",
    "\n",
    "    # isOriginalTitle validation\n",
    "    df = df.withColumn(\n",
    "        \"has_valid_is_original\",\n",
    "        col(\"is_original_valid\")\n",
    "    )\n",
    "\n",
    "    # ===========================\n",
    "    # COMPLETENESS SCORE\n",
    "    # ===========================\n",
    "    # Score based on presence of key fields (max 100)\n",
    "    df = df.withColumn(\n",
    "        \"data_completeness_score\",\n",
    "        (\n",
    "            when(col(\"titleId_valid\"), lit(25)).otherwise(lit(0))  # titleId is most important\n",
    "            + when(col(\"title_clean\").isNotNull(), lit(25)).otherwise(lit(0))  # title is essential\n",
    "            + when(col(\"ordering_clean\").isNotNull(), lit(15)).otherwise(lit(0))\n",
    "            + when(col(\"region_clean\").isNotNull(), lit(15)).otherwise(lit(0))\n",
    "            + when(col(\"language_clean\").isNotNull(), lit(10)).otherwise(lit(0))\n",
    "            + when(size(col(\"types_array\")) > 0, lit(5)).otherwise(lit(0))\n",
    "            + when(col(\"is_original_flag\").isNotNull(), lit(5)).otherwise(lit(0))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"quality_tier\",\n",
    "        when(col(\"data_completeness_score\") >= 80, \"HIGH\")\n",
    "        .when(col(\"data_completeness_score\") >= 60, \"MEDIUM\")\n",
    "        .when(col(\"data_completeness_score\") >= 40, \"LOW\")\n",
    "        .otherwise(\"POOR\")\n",
    "    )\n",
    "\n",
    "    # ===========================\n",
    "    # PROCESSING METADATA\n",
    "    # ===========================\n",
    "    df = df.withColumn(\"silver_processing_timestamp\", current_timestamp())\n",
    "    df = df.withColumn(\"silver_processing_date\", current_timestamp().cast(\"date\"))\n",
    "    df = df.withColumn(\"silver_version\", lit(\"2.0\"))  # Updated version with proper validation\n",
    "\n",
    "    # ===========================\n",
    "    # QUALITY CHECK DECISION\n",
    "    # ===========================\n",
    "    # Only truly invalid records go to quarantine\n",
    "    df = df.withColumn(\n",
    "        \"silver_quality_check\",\n",
    "        when(~col(\"titleId_valid\"), \"FAILED\")  # Invalid titleId is critical\n",
    "        .when(~col(\"has_valid_ordering\"), \"FAILED\")\n",
    "        .when(~col(\"has_valid_region\"), \"FAILED\")\n",
    "        .when(~col(\"has_valid_language\"), \"FAILED\")\n",
    "        .when(~col(\"has_valid_types\"), \"FAILED\")\n",
    "        .when(~col(\"has_valid_is_original\"), \"FAILED\")\n",
    "        .otherwise(\"PASSED\")\n",
    "    )\n",
    "\n",
    "    # Add failure reason for debugging\n",
    "    df = df.withColumn(\n",
    "        \"quality_failure_reason\",\n",
    "        when(~col(\"titleId_valid\"), \"Invalid titleId format (expected tt[0-9]+)\")\n",
    "        .when(~col(\"has_valid_ordering\"), \"Invalid ordering value\")\n",
    "        .when(~col(\"has_valid_region\"), \"Invalid region code\")\n",
    "        .when(~col(\"has_valid_language\"), \"Invalid language code\")\n",
    "        .when(~col(\"has_valid_types\"), \"Invalid type value (not in enumerated list)\")\n",
    "        .when(~col(\"has_valid_is_original\"), \"Invalid isOriginalTitle (expected 0 or 1)\")\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "    # Deduplicate by (titleId, ordering), keep latest ingestion\n",
    "    w = Window.partitionBy(\"titleId\", \"ordering\").orderBy(col(\"bronze_ingestion_timestamp\").desc())\n",
    "    df = df.withColumn(\"rn\", row_number().over(w)).filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# 6. SILVER CLEAN (NO NULLS, READY FOR GOLD)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_silver_clean\",\n",
    "    comment=\"High-quality Silver records for title.akas with validated fields ready for Gold layer\"\n",
    ")\n",
    "def title_akas_silver_clean():\n",
    "    \"\"\"\n",
    "    Filter to only PASSED records and provide clean, standardized output schema.\n",
    "    All NULL values replaced with sensible defaults.\n",
    "    \"\"\"\n",
    "    df = dlt.read(\"title_akas_silver_all\").filter(col(\"silver_quality_check\") == \"PASSED\")\n",
    "\n",
    "    return df.select(\n",
    "        # Primary keys / identifiers\n",
    "        col(\"titleId\").alias(\"title_imdb_id\"),\n",
    "        coalesce(col(\"ordering_clean\"), lit(0)).alias(\"ordering\"),\n",
    "\n",
    "        # Title information\n",
    "        coalesce(col(\"title_clean\"), lit(\"Unknown\")).alias(\"aka_title\"),\n",
    "\n",
    "        # Region / language (validated codes)\n",
    "        coalesce(col(\"region_clean\"), lit(\"unknown\")).alias(\"region_code\"),\n",
    "        coalesce(col(\"language_clean\"), lit(\"unknown\")).alias(\"language_code\"),\n",
    "\n",
    "        # Types / attributes as arrays\n",
    "        col(\"types_array\").alias(\"types\"),\n",
    "        col(\"attributes_array\").alias(\"attributes\"),\n",
    "        col(\"types_count\"),\n",
    "        col(\"attributes_count\"),\n",
    "\n",
    "        # Original title flag\n",
    "        coalesce(col(\"is_original_flag\"), lit(False)).alias(\"is_original_title\"),\n",
    "\n",
    "        # Quality metrics\n",
    "        col(\"data_completeness_score\"),\n",
    "        col(\"quality_tier\"),\n",
    "\n",
    "        # Silver layer audit\n",
    "        col(\"silver_processing_timestamp\"),\n",
    "        col(\"silver_processing_date\"),\n",
    "        col(\"silver_version\"),\n",
    "\n",
    "        # Bronze layer lineage\n",
    "        col(\"bronze_ingestion_timestamp\"),\n",
    "        col(\"bronze_ingestion_date\"),\n",
    "        col(\"bronze_source_system\"),\n",
    "        col(\"bronze_source_file\"),\n",
    "        col(\"bronze_record_hash\")\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# 7. QUARANTINE\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_quarantine\",\n",
    "    comment=\"Records from title.akas that failed Silver quality checks with failure reasons\"\n",
    ")\n",
    "def title_akas_quarantine():\n",
    "    \"\"\"\n",
    "    Capture all failed records with diagnostic information for investigation.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        dlt.read(\"title_akas_silver_all\")\n",
    "        .filter(col(\"silver_quality_check\") == \"FAILED\")\n",
    "        .select(\n",
    "            # Original values for investigation\n",
    "            col(\"titleId\"),\n",
    "            col(\"ordering\"),\n",
    "            col(\"title\"),\n",
    "            col(\"region\"),\n",
    "            col(\"language\"),\n",
    "            col(\"types\"),\n",
    "            col(\"attributes\"),\n",
    "            col(\"isOriginalTitle\"),\n",
    "            \n",
    "            # Validation results\n",
    "            col(\"titleId_valid\"),\n",
    "            col(\"has_valid_ordering\"),\n",
    "            col(\"has_valid_region\"),\n",
    "            col(\"has_valid_language\"),\n",
    "            col(\"has_valid_types\"),\n",
    "            col(\"has_valid_is_original\"),\n",
    "            \n",
    "            # Failure information\n",
    "            col(\"silver_quality_check\"),\n",
    "            col(\"quality_failure_reason\"),\n",
    "            \n",
    "            # Audit columns\n",
    "            col(\"bronze_ingestion_timestamp\"),\n",
    "            col(\"bronze_source_file\"),\n",
    "            col(\"bronze_record_hash\"),\n",
    "            col(\"silver_processing_timestamp\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# 8. DATA QUALITY METRICS (OPTIONAL AGGREGATION TABLE)\n",
    "# ============================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"title_akas_quality_metrics\",\n",
    "    comment=\"Aggregated data quality metrics for title.akas pipeline monitoring\"\n",
    ")\n",
    "def title_akas_quality_metrics():\n",
    "    \"\"\"\n",
    "    Aggregate quality metrics for pipeline monitoring and alerting.\n",
    "    \"\"\"\n",
    "    df = dlt.read(\"title_akas_silver_all\")\n",
    "    \n",
    "    return df.groupBy(\"silver_processing_date\").agg(\n",
    "        expr(\"count(*) as total_records\"),\n",
    "        expr(\"sum(case when silver_quality_check = 'PASSED' then 1 else 0 end) as passed_records\"),\n",
    "        expr(\"sum(case when silver_quality_check = 'FAILED' then 1 else 0 end) as failed_records\"),\n",
    "        expr(\"round(sum(case when silver_quality_check = 'PASSED' then 1 else 0 end) * 100.0 / count(*), 2) as pass_rate_pct\"),\n",
    "        \n",
    "        # Breakdown by validation type\n",
    "        expr(\"sum(case when NOT titleId_valid then 1 else 0 end) as invalid_title_id_count\"),\n",
    "        expr(\"sum(case when NOT has_valid_ordering then 1 else 0 end) as invalid_ordering_count\"),\n",
    "        expr(\"sum(case when NOT has_valid_region then 1 else 0 end) as invalid_region_count\"),\n",
    "        expr(\"sum(case when NOT has_valid_language then 1 else 0 end) as invalid_language_count\"),\n",
    "        expr(\"sum(case when NOT has_valid_types then 1 else 0 end) as invalid_types_count\"),\n",
    "        expr(\"sum(case when NOT has_valid_is_original then 1 else 0 end) as invalid_is_original_count\"),\n",
    "        \n",
    "        # Quality tier distribution\n",
    "        expr(\"sum(case when quality_tier = 'HIGH' then 1 else 0 end) as high_quality_count\"),\n",
    "        expr(\"sum(case when quality_tier = 'MEDIUM' then 1 else 0 end) as medium_quality_count\"),\n",
    "        expr(\"sum(case when quality_tier = 'LOW' then 1 else 0 end) as low_quality_count\"),\n",
    "        expr(\"sum(case when quality_tier = 'POOR' then 1 else 0 end) as poor_quality_count\"),\n",
    "        \n",
    "        # Average completeness\n",
    "        expr(\"round(avg(data_completeness_score), 2) as avg_completeness_score\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze_silver_titleakas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
